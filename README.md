# Pipeline ETL - Nettoyage, Transformation et Validation de DonnÃ©es

> Ce projet Python propose un pipeline ETL complet et dynamique permettant de traiter, enrichir et valider automatiquement un jeu de donnÃ©es. Il inclut une gestion robuste des erreurs, une journalisation, et une validation croisÃ©e pour assurer la qualitÃ© des donnÃ©es.

## ğŸ›  FonctionnalitÃ©s principales

- Analyse initiale : dimensions, valeurs manquantes, doublons, valeurs aberrantes
- Nettoyage automatisÃ© : traitement des valeurs manquantes, suppression dâ€™anomalies, dÃ©doublonnage
- Transformation enrichie : colonnes calculÃ©es, catÃ©gories, normalisation
- AgrÃ©gation : rÃ©sumÃ©s statistiques par produit
- Validation finale : contrÃ´les qualitÃ© automatiques, validation croisÃ©e
- Logging intÃ©grÃ© et gestion des erreurs (try/except)
- Sauvegarde des fichiers nettoyÃ©s et agrÃ©gÃ©s

## ğŸ“¦ DÃ©pendances

- `pandas`
- `numpy`
- `logging` (standard)
- `datetime` (standard)

## ğŸš€ Exemple dâ€™utilisation

```python
from pipeline_etl import pipeline_etl_complet

# ExÃ©cution du pipeline
pipeline_etl_complet("donnees_ventes.csv")
```

## ğŸ“Š Ã‰tapes du Pipeline

### 1. Chargement
Lecture des donnÃ©es via `pandas.read_csv()`

### 2. Analyse des donnÃ©es
- Affichage des dimensions
- Comptage des valeurs manquantes par colonne
- DÃ©tection de doublons (gÃ©nÃ©raux et sur les IDs)
- Identification des valeurs aberrantes (nÃ©gatifs et zÃ©ros)

### 3. Nettoyage
- Remplacement des valeurs manquantes :
  - `Nom_produit` â†’ "Produit_Inconnu"
  - `Quantite_vendue` â†’ mÃ©diane
  - `Prix_unitaire` â†’ moyenne
- Suppression des valeurs aberrantes (nÃ©gatives, prix Ã  0)
- Plafonnement des extrÃªmes par mÃ©thode IQR
- Suppression des doublons (ligne complÃ¨te et par ID)

### 4. Transformations
- Colonnes calculÃ©es : `Chiffre_affaires`, `Timestamp_traitement`
- CatÃ©gorisation : `Categorie_prix`, `Categorie_volume`
- Normalisation min-max : `Quantite_vendue`, `Prix_unitaire`, `Chiffre_affaires`

### 5. AgrÃ©gation
- Groupement par `Nom_produit`
- Statistiques : somme, moyenne, min/max, nombre de ventes
- CrÃ©ation dâ€™une colonne `Performance` basÃ©e sur le chiffre dâ€™affaires total

### 6. Validation
- ContrÃ´le des valeurs manquantes et doublons
- UnicitÃ© des IDs
- PrÃ©sence des colonnes transformÃ©es
- Validation croisÃ©e du chiffre d'affaires

### 7. Sauvegarde
- Fichier nettoyÃ© : `*_nettoye.csv`
- Fichier agrÃ©gats : `*_agregats.csv`

## ğŸ” Exemple de test intÃ©grÃ©

Le script contient une fonction `test_pipeline()` qui permet de tester automatiquement le pipeline avec des donnÃ©es synthÃ©tiques. Ce test inclut des cas de valeurs manquantes, doublons et valeurs aberrantes pour valider le bon fonctionnement de bout en bout.

## ğŸ“ Structure attendue

```
.
â”œâ”€â”€ pipeline_etl.py
â”œâ”€â”€ jeu_donnees_etl_5000_lignes.csv
â”œâ”€â”€ jeu_donnees_etl_5000_lignes_nettoye.csv
â”œâ”€â”€ jeu_donnees_etl_5000_lignes_agregats.csv
â””â”€â”€ README.md
```

## âœ… RÃ©sultats attendus

- DonnÃ©es nettoyÃ©es, transformÃ©es et enrichies
- AgrÃ©gats synthÃ©tiques par produit
- Journaux d'exÃ©cution clairs
- Validation automatisÃ©e des donnÃ©es
- ExÃ©cution robuste mÃªme en cas dâ€™erreurs

## ğŸ§ª Test automatique

Le pipeline est automatiquement testable via une entrÃ©e console pour choisir le jeu de donnÃ©es de test synthÃ©tique ou rÃ©el.

---

Â© Projet pÃ©dagogique de traitement de donnÃ©es pour lâ€™analyse ETL avec Python. Toutes les donnÃ©es sont fictives.
